# TPC 4 - Analisador L√©xico de C√≥digo

**Autor:** [Maria Cleto Rocha]  
**N√∫mero:** [A104441]

![Fotografia do Estudante](mariafoto.jpeg)

---

## Introdu√ß√£o e Descri√ß√£o
Este ficheiro foi desenvolvido no √¢mbito da Unidade Curricular de **Processamento de Linguagens**. O objetivo do mesmo √© implementar um analisador l√©xico que processa c√≥digos, extraindo e classificando os diferentes tokens presentes no c√≥digo.  
A aplica√ß√£o utiliza express√µes regulares para identificar e diferenciar elementos como coment√°rios, strings, n√∫meros, vari√°veis, palavras-chave e identificadores, permitindo assim a an√°lise e interpreta√ß√£o do c√≥digo fornecido.

---

## Regras de Funcionamento
1. **Defini√ß√£o dos Tokens**:  
   - S√£o definidas diversas especifica√ß√µes de tokens, cada uma associada a uma express√£o regular.  
   - Exemplos:  
     - `COMMENT` para coment√°rios (iniciados por `#`);  
     - `STRING` para literais de string delimitados por aspas;  
     - `NUMBER` para sequ√™ncias num√©ricas;  
     - `VARIABLE` para vari√°veis que iniciam com `?`;  
     - `KEYWORD` para palavras reservadas como `select`, `SELECT`,`WHERE`, `where` e `LIMIT`;  
     - `IDENTIFIER` para nomes que seguem um padr√£o de identificador.  

2. **Processo de Tokeniza√ß√£o**:  
   - A fun√ß√£o `tokenize(code)` compila todas as express√µes regulares num √∫nico padr√£o e percorre o c√≥digo utilizando `re.finditer`.  
   - Para cada correspond√™ncia encontrada, o token √© classificado de acordo com o seu tipo.  
   - Tokens de espa√ßos em branco e coment√°rios s√£o ignorados.  
   - Caso seja detectado um caractere que n√£o se enquadre em nenhum token (definido como `MISMATCH`), √© levantada uma exce√ß√£o.

3. **Exemplo de Execu√ß√£o**:  
   - Ao executar o script, um exemplo de c√≥digo (contendo uma consulta similar a SPARQL) √© analisado e os tokens extra√≠dos s√£o impressos no terminal.

---

## Arquitetura do Programa
- **Fun√ß√£o `tokenize(code)`**:  
  - **Constru√ß√£o do Regex**:  
    - Cria uma express√£o regular composta, combinando todas as especifica√ß√µes de tokens.
  - **Itera√ß√£o e Classifica√ß√£o**:  
    - Utiliza `re.finditer` para identificar e classificar cada token presente no c√≥digo.  
    - Converte tokens num√©ricos para inteiros e ignora espa√ßos e coment√°rios.
  - **Gest√£o de Erros**:  
    - Se um caractere n√£o corresponder a nenhum padr√£o esperado, o programa gera um erro com uma mensagem de "Caractere inesperado".

- **Bloco Principal (`if __name__ == '__main__':`)**:  
  - Define um exemplo de c√≥digo que simula uma consulta com uma sintaxe similar a SPARQL.  
  - Chama a fun√ß√£o `tokenize` para processar o exemplo e imprime os tokens resultantes.

---

## C√≥digo Fonte
O c√≥digo completo pode ser encontrado no seguinte reposit√≥rio (exemplo de link):  
[üîó analisadorlex.py](https://github.com/MariaCletoR/PL2025-A104441/blob/main/TPC4/analisadorlex.py)

---

## Execu√ß√£o
Para executar o analisador l√©xico, certifique-se de ter o Python 3 instalado e utilize o comando abaixo (garantindo que o script se encontra na mesma pasta):

```sh
python3 analisadorlex.py


